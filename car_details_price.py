# -*- coding: utf-8 -*-
"""car_details_price

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ha-P6MdQi9GoWMCncoh1mW9pZrCj7YGX

# **Project Name**    -  Car Price Prediction Using Regression model

##### **Project Type**    - Regression
##### **Contribution**    - Individual
##### **Cntributor -** - Ratnesh Verma

# **Project Summary -**

This dataset comprises a wealth of information regarding used cars, including details such as the year in which the car was manufactured, the selling price, the amount of kilometers driven, the type of fuel used, the type of seller (whether a dealer or an individual), the type of transmission (automatic or manual), and the number of previous owners. 

the task at hand is to apply various machine learning regression models to the provided used car dataset, with the objective of accurately predicting the selling price of the cars based on the available features. This could involve using multiple linear regression, polynomial regression, decision tree regression, random forest regression, or other suitable regression models. The ultimate goal is to identify the model or combination of models that yields the most accurate and reliable price predictions for the used cars in the dataset.

# **GitHub Link -**

**Problem Statement**

the task at hand is to apply various machine learning regression models to the provided used car dataset, with the objective of accurately predicting the selling price of the cars based on the available features. This could involve using multiple linear regression, polynomial regression, decision tree regression, random forest regression, or other suitable regression models. The ultimate goal is to identify the model or combination of models that yields the most accurate and reliable price predictions for the used cars in the dataset.

# ***Let's Begin !***

## ***1. Know Your Data***
"""

# Commented out IPython magic to ensure Python compatibility.
# Import Libraries
import pandas as pd
import numpy as np
import scipy
import matplotlib as mpl
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from datetime import datetime

import warnings    
warnings.filterwarnings('ignore')

#mounting drive
from google.colab import drive
drive.mount('/content/drive')

"""### Dataset First View"""

#Importing data set
df =pd.read_csv("/content/drive/MyDrive/CAR DETAILS (1).csv")

df.head()

"""### Dataset Rows & Columns count"""

# Dataset Rows & Columns count
print('The number of rows in data is:',df.shape[0])
print('The number of columns in data is',len(list(df.columns)))

"""### Dataset Information"""

# Dataset Info
df.info()

"""#### Duplicate Values"""

# Dataset Duplicate Value Count
# df.duplicated().sum()
duplicate_rows_in_store_data = df.duplicated().sum()
print('The number of duplicates rows in the data is:',duplicate_rows_in_store_data)

"""#### Missing Values/Null Values"""

# Missing Values/Null Values Count
df.isnull().sum()

"""### What did you know about your dataset?

1. -There is no null value present in the data set.
2. -There are 8 columns in the dataset.
3. -The number of duplicate row in the dataset is 763.

## ***2. Understanding Your Variables***
"""

# Dataset Columns
print(list(df.columns))

# checking information about the data type of the variable
df.info()

# Dataset Describe
df.describe()

"""### Check Unique Values for each variable."""

#checking number of unique cars available in the data set
df['name'].nunique()

# Check Unique Values for each variable.

for col in df.columns:
  print(f'The unique values in {col} are {df[col].unique()}' )

"""## ***3.Data Wrangling and visualization***"""

# Get the counts of each category in the column
counts = df['fuel'].value_counts()

# Create a pie chart
fig, ax = plt.subplots(figsize=(10, 10))
plt.pie(counts.values, labels=counts.index, autopct='%1.1f%%' , startangle=45 , textprops={'fontsize': 10})
plt.axis('equal')
plt.title('Car_type')
plt.show()

unique_car = df["name"].nunique()
print("The number of unique car count variables is:", unique_car)

car_owner = df.groupby("owner")["name"].count().reset_index().rename(columns={"name": "count"})
car_owner

plt.figure(figsize=(13,8))
plt.title('car_owner Type')
sns.barplot(x='owner',y='count',data=car_owner)

df.head(2)

selling_price = df.groupby("fuel")["selling_price"].sum().reset_index()
selling_price

plt.figure(figsize=(13,8))
plt.title('max_sell_CAR_Type')
sns.barplot(x='fuel',y='selling_price',data=selling_price)

# Chart - 4 visualization code
newlist=df['owner'].unique()
y=list(newlist)
# Applying for loop operation
for x in y:
  sub_1=df.loc[df['owner'] == x]
  p_sub1=sub_1.groupby(['owner'])['selling_price'].value_counts().head(3)
  print(p_sub1)
  plt.figure(figsize=(5,3))
  p_sub1.plot(kind='bar')
  plt.title('Top 3 sold car of '+str(x))
  plt.xlabel("car")
  plt.ylabel("Counting")

df_plot = df.groupby(['seller_type'])['name'].count().reset_index().rename(columns={"name": "count"})

df_plot

#visualization code
#Writing a code for plotting line plot between the target variable and age, cigsPerDay, and heartRate
plt.figure(figsize=(10, 6))
sns.lineplot(x='km_driven', y="selling_price", data=df.head(200))

df.head(1)

#Here we can see that on an average selling price of each fuel type car in each year 
# Chart - 9 visualization code
plt.figure(figsize=(30,10))
ax=sns.barplot(x=df['year'], y=df['selling_price'],hue=df['fuel'])
plt.show()

#Lets check the selling price of manual and automatic cars
plt.figure(figsize=(10,16))
ax=sns.boxplot(x=df['transmission'], y=df['selling_price'])
plt.show()

"""## ***4. Feature Engineering & Data Pre-processing***

"""

df1 = df [['year', 'selling_price', 'km_driven',
       'fuel', 'seller_type', 'transmission', 'owner']]

df1['Current_Year'] = 2022

df1.head()

#Creating our new column no_of_year
df1['Year_old'] = df1['Current_Year'] - df1['year']

#One Hot Encoding for Categorical variables by creating dummy variables
df1 = pd.get_dummies(df1, drop_first = True)

df1.drop(['year','Current_Year'], axis=1, inplace=True)

df1.head()

"""### 2. Handling Outliers"""

#plotting distribution plot of target Variables
sns.distplot(x=df1.selling_price)

#plotting distribution plot of target Variables
sns.distplot(x=df1.km_driven)

"""A Distplot or distribution plot, depicts the variation in the data distribution. Seaborn Distplot represents the overall distribution of continuous data variables i.e. data distribution of a variable against the density distribution. In above graph we can see that our graph have right tail(right skewed) it means tha our most of data centered near peak of the graph but there is a some highly expensive price that leads to a seperate trends that's why our graph showing right trends."""

# calculate the upper and lower limits for the km_driven column using the capping method
Q1 = df1["km_driven"].quantile(0.25)
Q3 = df1["km_driven"].quantile(0.75)
IQR = Q3 - Q1
upper_limit = Q3 + 1.5*IQR
lower_limit = Q1 - 1.5*IQR

# replace outliers above the upper limit with the nearest non-outlier value, and outliers below the lower limit with the nearest non-outlier value
df1["km_driven"] = np.where(df1["km_driven"] > upper_limit, df1["km_driven"].quantile(0.95), df1["km_driven"])
df1["km_driven"] = np.where(df1["km_driven"] < lower_limit, df1["km_driven"].quantile(0.05), df1["km_driven"])

"""In above, the upper and lower limits are calculated using the interquartile range (IQR) multiplied by 1.5. Any values above the upper limit or below the lower limit are replaced with the 99th or 1st percentile value, respectively, using the NumPy where function"""

sns.distplot(x=df1.km_driven)

df1["km_driven_sqrt"] = np.sqrt(df1["km_driven"])

sns.distplot(x=df1.km_driven_sqrt)

"""After transforming the data now we can see that our data looks good and Logarithmic transformation converted our data to a normal distribution. It is a type of data transformation that can be applied to data that has a wide range of values or is skewed in one direction."""

# take the natural logarithm of a column called "column_to_transform"
df1["selling_price"] = np.log(df1["selling_price"])

#plotting distribution plot of target Variables
sns.distplot(x=df1.selling_price)

"""Logarithmic transformation is a mathematical operation used in data analysis and modeling to convert data that is not normally distributed to a normal distribution. It is a type of data transformation that can be applied to data that has a wide range of values or is skewed in one direction."""

df1.head()

#dropping un_necessary colmns
df1.drop(['km_driven'], axis=1, inplace=True)

df1.columns

"""#### 2. Feature Selection"""

from sklearn.ensemble import RandomForestRegressor

# define your feature matrix X and target variable y
X = df1.drop('selling_price', axis=1)
y = df1['selling_price']

# train a Random Forest regressor
rf = RandomForestRegressor()
rf.fit(X, y)

# get feature importances and put them into a DataFrame
importances = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_})

# sort the DataFrame by importance (descending)
importances = importances.sort_values('importance', ascending=False)

# print the top 10 features by importance
print(importances.head(16))

import matplotlib.pyplot as plt

# create a bar chart of feature importances
plt.bar(importances['feature'], importances['importance'])
plt.xticks(rotation=90)
plt.ylabel('Importance')
plt.xlabel('Feature')
plt.show()

#removing un-necessary features
df1.drop(['fuel_LPG', 'owner_Test Drive Car','fuel_Electric' ], axis=1, inplace=True)

df1.columns

"""### 6. Data Scaling

StandardScaler is a popular method for scaling numerical data, typically used in machine learning and data analysis. It transforms your data so that it has a mean of 0 and a standard deviation of 1.

StandardScaler is a commonly used scaling method that scales the data to have zero mean and unit variance. This ensures that the features are on the same scale and have similar ranges. Scaling is generally considered a good practice in machine learning and data analysis, and is often a necessary step in the preprocessing pipeline
"""

#making copy
df2=df1.copy()

#importing libraray
from sklearn.preprocessing import StandardScaler

#convering data type
df2['Year_old'] = df2['Year_old'].astype(float)

# Scaling your data
#applying standardScaler 
scaler = StandardScaler()
df3 = scaler.fit_transform(df2)

#converting back to dataframe
df3 = pd.DataFrame(df3, columns=df2.columns)

df3.head()

"""### 8. Data Splitting"""

import numpy as np
import pandas as pd
from numpy import math

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

# Split your data to train and test. Choose Splitting ratio wisely.
x, y = df3.loc[:, df3.columns != 'selling_price'], df3['selling_price']

#importing library to split
from sklearn.model_selection import train_test_split
#dividing the data for training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 0)
print(x_train.shape)
print(x_test.shape)

"""## ***5. ML Model Implementation***"""

# create a dataframe to store metrics related to models
metrics_table = pd.DataFrame(columns=['Regression_Model', 'Train_R2', 'Test_R2', 'Train_RMSE', 'Test_RMSE', 'Train_RMSPE', 'Test_RMSPE'])

# define a function to calculate root mean squared percentage error
# returns an array
def calculate_rmspe(y, y_pred):
  return (np.sqrt(np.mean(np.square(y.to_numpy() - y_pred))) / np.mean(y.to_numpy())) * 100

# define a function to calculate metrics
# returns a dictionary
def calculate_model_metrics(y_train, y_train_pred, y_test, y_test_pred):
  metrics_dict = {}

  metrics_dict['Train_R2'] = r2_score(y_train, y_train_pred)
  metrics_dict['Test_R2'] = r2_score(y_test, y_test_pred)
  metrics_dict['Train_RMSE'] = mean_squared_error(y_train, y_train_pred, squared=False)
  metrics_dict['Test_RMSE'] = mean_squared_error(y_test, y_test_pred, squared=False)
  metrics_dict['Train_RMSPE'] = calculate_rmspe(y_train, y_train_pred)
  metrics_dict['Test_RMSPE'] = calculate_rmspe(y_test, y_test_pred)

  return metrics_dict

"""### ML Model - 1 Linear Regression"""

# ML Model - 1 Implementation
# Fit the Algorithm
# Predict on the model

from sklearn.linear_model import LinearRegression
regression_model = LinearRegression()
regression_model.fit(x_train, y_train)

regression_model.score(x_test, y_test)

#checking prediction
y_train_pred = regression_model.predict(x_train)
y_test_pred = regression_model.predict(x_test)

#calculating for model metrics
model_evaluation = calculate_model_metrics(y_train, y_train_pred, y_test, y_test_pred)

#storing data in metric tables
metrics_table.loc[len(metrics_table.index)] = ['Linear', model_evaluation['Train_R2'], model_evaluation['Test_R2'], 
                                                         model_evaluation['Train_RMSE'], model_evaluation['Test_RMSE'], 
                                                         model_evaluation['Train_RMSPE'], model_evaluation['Test_RMSPE']]

"""#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.

We have used Linear Regression as our first model, Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting.
"""

metrics_table

"""#### 2. Cross- Validation & Hyperparameter Tuning"""

# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
# Fit the Algorithm
# Predict on the model

# cross validation using k fold technique
from sklearn.model_selection import cross_val_score
for i in [3,5,10]:
  score = cross_val_score(LinearRegression(), x_train, y_train,cv=i)
  print(np.average(score))

#hyper parameter tuning using RandomizedSearchCV
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

lr = LinearRegression()

param_distributions = {"fit_intercept": [True, False],
                        "copy_X": [True, False],
                       "positive": [True, False]}
search = RandomizedSearchCV(lr, param_distributions).fit(x, y)
search.best_score_

c=search.best_params_

# Fit the model on the entire training data using best hyperparameters
lr = LinearRegression(fit_intercept=c["fit_intercept"], copy_X=c["copy_X"], positive=c["positive"])
lr.fit(x_train, y_train)

# Predict the target variable for test data using the trained model
y_pred = lr.predict(x_test)

# Evaluate the model performance on test data
from sklearn.metrics import r2_score, mean_squared_error

print("R^2 score:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))

"""##### Which hyperparameter optimization technique have you used and why?

Over here we have used **RandomizedSearchCV** hyperparameter optimization technique , the reason for using this technique is that In order to train and score the model, Random Search creates a grid of hyperparameter values and chooses random combinations. As a result, we are able to specifically regulate the quantity of parameter combinations that are tried. Based on available time or resources, the number of search iterations is decided.

##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.

We have seen slight fall in the accuracy of the model by using the hyperparameter tuning.

###ML Model - 2 Decision Tree Regressor

#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.
"""

from sklearn.tree import DecisionTreeRegressor
decision_tree_model = DecisionTreeRegressor()
decision_tree_model.fit(x_train, y_train)

decision_tree_model.score(x_test, y_test)

# predict the train and test data
y_train_pred = decision_tree_model.predict(x_train)
y_test_pred = decision_tree_model.predict(x_test)

model_evaluation = calculate_model_metrics(y_train, y_train_pred, y_test, y_test_pred)

metrics_table.loc[len(metrics_table.index)] = ['Decision Tree', model_evaluation['Train_R2'], model_evaluation['Test_R2'], 
                                                         model_evaluation['Train_RMSE'], model_evaluation['Test_RMSE'], 
                                                         model_evaluation['Train_RMSPE'], model_evaluation['Test_RMSPE']]

"""Over here we have used Decision tree regressor, Decision tree regression observes features of an object and trains a model in the structure of a tree to predict data in the future to produce meaningful continuous output. Continuous output means that the output/result is not discrete, i.e., it is not represented just by a discrete, known set of numbers or values."""

metrics_table.loc[1:,:]

"""#### 2. Cross- Validation & Hyperparameter Tuning"""

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score
from pylab import rcParams

# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
# Fit the Algorithm
# Predict on the model
# cross validation using k fold technique
from sklearn.model_selection import cross_val_score
for i in [3,5,10]:
  score = cross_val_score(DecisionTreeRegressor(), X, y,cv=i)
  print(np.mean(score))

#hyper parameter tuning using RandomizedSearchCV
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

dtr = DecisionTreeRegressor()

param_distributions = {"criterion": ["squared_error", "poisson","friedman_mse" ],
                        "splitter": ["best", "random"],
                       "max_features": ["auto", "sqrt", "log2"], "max_depth" : [10]}
search = RandomizedSearchCV(dtr, param_distributions).fit(X, y)
search.best_score_

search.best_params_

"""##### Which hyperparameter optimization technique have you used and why?

Over here we have used RandomizedSearchCV hyperparameter optimization technique , the reason for using this technique is that In order to train and score the model, Random Search creates a grid of hyperparameter values and chooses random combinations. As a result, we are able to specifically regulate the quantity of parameter combinations that are tried. Based on available time or resources, the number of search iterations is decided.

##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.

We have seen slight fall in the accuracy of the model by using the hyperparameter tuning.

#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used.

Evaluation metrics are used in machine learning to measure the performance of a model on a given dataset. This allows us to compare the performance of different models and select the one that performs the best on the task at hand. we have used evaluation metrics for this tasks, mean squared error for regression problems , RMSE.

###ML Model - 3 Random Forest Regressor

####1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.
"""

from sklearn.ensemble import RandomForestRegressor
random_forest_model = RandomForestRegressor()
random_forest_model.fit(x_train, y_train)

random_forest_model.score(x_test, y_test)

# predict the train and test data
y_train_pred = random_forest_model.predict(x_train)
y_test_pred = random_forest_model.predict(x_test)

# model evaluation
model_evaluation = calculate_model_metrics(y_train, y_train_pred, y_test, y_test_pred)

# add metrics to metrics table
metrics_table.loc[len(metrics_table.index)] = ['Random Forest', model_evaluation['Train_R2'], model_evaluation['Test_R2'], 
                                                                model_evaluation['Train_RMSE'], model_evaluation['Test_RMSE'], 
                                                                model_evaluation['Train_RMSPE'], model_evaluation['Test_RMSPE']]

"""A supervised learning technique called Random Forest Regression leverages the ensemble learning approach for regression. The ensemble learning method combines predictions from various machine learning algorithms to provide predictions that are more accurate than those from a single model.

### ML Model - 4 Lasso and Ridge Regression (L1 and L2 Regularization)
"""

# ML Model - 3 Implementation
# Fit the Algorithm
# Predict on the model
from sklearn.linear_model import Lasso, Ridge, ElasticNet
lasso_model = Lasso()
lasso_model.fit(x_train, y_train)

lasso_model.score(x_test, y_test)

#ridge REgression
ridge_model = Ridge()
ridge_model.fit(x_train, y_train)
ridge_model.score(x_test, y_test)

# predict the train and test data
y_train_pred = ridge_model.predict(x_train)
y_test_pred = ridge_model.predict(x_test)

# model evaluation
model_evaluation = calculate_model_metrics(y_train, y_train_pred, y_test, y_test_pred)

# add metrics to metrics table
metrics_table.loc[len(metrics_table.index)] = ['Ridge', model_evaluation['Train_R2'], model_evaluation['Test_R2'], 
                                                                model_evaluation['Train_RMSE'], model_evaluation['Test_RMSE'], 
                                                                model_evaluation['Train_RMSPE'], model_evaluation['Test_RMSPE']]

#elasticnet regression
elasticnet_model = ElasticNet()
elasticnet_model.fit(x_train, y_train)
elasticnet_model.score(x_test, y_test)

"""#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.

Evaluation metrics are used in machine learning to measure the performance of a model on a given dataset. This allows us to compare the performance of different models and select the one that performs the best on the task at hand. we have used evaluation metrics for this tasks, mean squared error for regression problems , RMSE.
"""

metrics_table.loc[3:,:]

"""#### 2. Cross- Validation & Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
lasso = Lasso()
parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10]}
lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)
lasso_regressor.fit(x_train, y_train)
# Predict on the model
print("The best fit alpha value is found out to be :" ,lasso_regressor.best_params_)
print("\nUsing ",lasso_regressor.best_params_, " the negative mean squared error is: ", lasso_regressor.best_score_)

# predict the train and test data
y_train_pred = lasso_regressor.predict(x_train)
y_test_pred = lasso_regressor.predict(x_test)

# model evaluation
model_evaluation = calculate_model_metrics(y_train, y_train_pred, y_test, y_test_pred)
# add metrics to metrics table
metrics_table.loc[len(metrics_table.index)] = ['Lasso', model_evaluation['Train_R2'], model_evaluation['Test_R2'], 
                                                        model_evaluation['Train_RMSE'], model_evaluation['Test_RMSE'], 
                                                        model_evaluation['Train_RMSPE'], model_evaluation['Test_RMSPE']]

"""##### Which hyperparameter optimization technique have you used and why?

Over here we have used GridSearchCV hyperparameter optimization technique , the reason for using this technique is that In order to train and score the model, grid Search creates a grid of hyperparameter values and chooses random combinations. As a result, we are able to specifically regulate the quantity of parameter combinations that are tried. Based on available time or resources, the number of search iterations is decided

##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.

We have seen highly jump in the accuracy of the model by using the hyperparameter tuning our lasso r2 score increase to .82

### 1. Which Evaluation metrics did you consider for a positive business impact and why?

Evaluation metrics are used in machine learning to measure the performance of a model on a given dataset. This allows us to compare the performance of different models and select the one that performs the best on the task at hand. we have used evaluation metrics for this tasks, mean squared error for regression problems , RMSE.Answer Here.

### 2. Which ML model did you choose from the above created models as your final prediction model and why?

As we have seen above that, Random Forest Regressor is performing the best with the accuracy of 97.3% followed by Decison Tree Regressor with accuracy of 94.3%
so here we are choosing Random Forest Regressor for best prediction.
"""

# print metrics table
metrics_table

"""### 3. Explain the model which you have used and the feature importance using any model explainability tool?

Random Forest is a supervised learning algorithm that can be used for both classification and regression tasks. A Random Forest regressor is a specific type of Random Forest that is used for regression tasks, which involve predicting a continuous output value (such as a price or temperature) rather than a discrete class label.

The algorithm works by creating an ensemble of decision trees, where each tree is trained on a random subset of the data. The final output is then obtained by averaging the predictions of all the trees. This helps to reduce overfitting and improve the overall performance of the model.

Random Forest regressor is known to be a very powerful algorithm that can handle high-dimensional data and a large number of input features. It is also relatively easy to use and interpret. It has several parameters that can be adjusted to optimize its performance, such as the number of trees in the ensemble, the maximum depth of each tree, and the minimum number of samples required to split a node.

### Here we are taking randomly 20 datapoints and predicting their price by the trained best model.
"""

#Here we are randomly taking 20 data points
sample_df = df3.sample(n=20)

# Here we are creating the target and feature variable
X, Y = sample_df.loc[:, sample_df.columns != 'selling_price'], sample_df['selling_price']

#predicted value
predict_20 = random_forest_model.predict(X)
predict_20

# Actual value
Y

#plot the actual and predicted value
plt.scatter(Y, predict_20)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs. Predicted Values")
plt.show()

#finding the r2 score
random_forest_model.score(X,Y)

metrics_table.loc[2:,:]

df.columns

features = X.columns
importances = random_forest_model.feature_importances_
indices = np.argsort(importances)
plt.figure(figsize=(8,10))
plt.title('Feature Importances', fontsize=20)
plt.barh(range(len(indices)), importances[indices], color='red', align='center')
plt.yticks(range(len(indices)), features[indices])
plt.xlabel('Relative Importance')

"""## ***6. Conclusion***

*   Before creating the regression model, it is crucial to clean and pre-process the data so
 that it is in the right format.
*   Unnecessary data that skew the results were also filtered out.


*   Feature engineering and exploratory data analysis were performed to gather more meaningful information from the data.
*   Apart from this, various data visualization, like box plot, frequency plot, histogram, pair plot, correlation matrix and scatter plot were created to understand the uni-variate distribution and multi-variate relationship of the data


*   Majority of cars are Diesel (49.6%) and Petrol (48.9%)
*   The number of unique car count is: 1491
*   Maximum sold cars belongs to First owners.
*   selling price of cars is decreasing as per their running status.
*   we performed Regression Analysis on our data set to model the prices of cars
 
**ML model**



*   Among the all regression models, it is clear that Random Forest Regressor is giving the best result with the accuracy of 72.4% followed by linear Regressor with accuracy of 69.2%. So, we will use the random forest regressor to predict the sales.

### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***
"""